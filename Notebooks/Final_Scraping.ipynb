{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d2a6ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import concurrent.futures\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c023fa8",
   "metadata": {},
   "source": [
    "### Functions that Will Extract Location and Address Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbce64cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##this function extracts the location (City State and Zipcode) for each school.\n",
    "\n",
    "def extractLocation(soup):\n",
    "    address_element = soup.select_one('address') \n",
    "        #print(address_element)\n",
    "        # Exclude the text within the span within the address element\n",
    "    if address_element:\n",
    "        city_state = address_element.find('span')\n",
    "    \n",
    "    else:\n",
    "        #print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
    "        return None  # Return None or some default value if the request fails\n",
    "\n",
    "    return city_state.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a6aa6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function extracts the address for each school.\n",
    "\n",
    "def extractAddress(soup):\n",
    "        # Find the address element\n",
    "    address_element = soup.select_one('address') \n",
    "        #print(address_element)\n",
    "        # Exclude the text within the span within the address element\n",
    "\n",
    "    city_state = address_element.find('span')\n",
    "    city_state.decompose()\n",
    "\n",
    "    address_text = address_element.get_text(strip=True)\n",
    "    if address_text != '':\n",
    "        return address_text\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7adff431",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function cleans up the location column by splitting it into city, state and zipcode columns.\n",
    "def splitLocation(column):\n",
    "    \n",
    "    pattern = r'(?P<city>[^,]+).\\s?(?P<state>\\w\\w)\\s?(?P<zipcode>\\d\\d\\d\\d\\d)?'\n",
    "    #column = pd.Series(column)\n",
    "    _city = column.str.extract(pattern)['city']\n",
    "    _state = column.str.extract(pattern)['state']\n",
    "    _zip = column.str.extract(pattern)['zipcode']\n",
    "    \n",
    "    return (_city, _state, _zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a67fca",
   "metadata": {},
   "source": [
    "### Functions that extract the Score and Game info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f814f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this funciton cleans up the gameinfo column by splitting it into venue, team2 and gametype (H or A) columns.\n",
    "def gameInfo(column):\n",
    "    pattern = r'(?P<venue>[vs@]*)(?P<name>[a-zA-Z]+(\\.|-)?\\s?[a-zA-Z]*\\'?\\w*)(?P<type>[*]*)'\n",
    "    # Apply str.extract to create new columns based on the pattern\n",
    "    _venue = column.str.extract(pattern)['venue']\n",
    "    _team2 = column.str.extract(pattern)['name']\n",
    "    _gametype = column.str.extract(pattern)['type']\n",
    "    \n",
    "    \n",
    "    return (_venue, _team2, _gametype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4c44032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function cleans up the score column by splitting it into team, team1_score and team2_score columns.\n",
    "def scoreInfo(column):\n",
    "    # Define a regular expression pattern to extract W or L, and the scores\n",
    "    pattern = r'([WL])(\\d+)-(\\d+)|([WL])\\(FF\\)'\n",
    "\n",
    "    # Extract the components into separate columns\n",
    "    extracted = column.str.extract(pattern)\n",
    "\n",
    "    # Assign extracted values to new columns\n",
    "    team = extracted[0].fillna(extracted[3])\n",
    "    team1_score = extracted[1]#.fillna(pd.NA).astype('Int64')\n",
    "    team2_score = extracted[2]#.fillna(pd.NA).astype('Int64')\n",
    "\n",
    "    return team, team1_score, team2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343bbc8e",
   "metadata": {},
   "source": [
    "### Functions that format the game and venue type correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0673f175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#each game entry will have  *, **, or *** next to it which correponds to the game type. This function cleans up the game type column.\n",
    "def cleanGameType(string):\n",
    "    #string = str(len(string))\n",
    "    if len(string) == 3:\n",
    "        string = 'Tournament'\n",
    "    elif len(string) == 2:\n",
    "        string = 'Playoff'\n",
    "    elif len(string) == 1:\n",
    "        string = 'District'\n",
    "    else:\n",
    "        string = 'Regular Season'\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a927d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanVenueType(string):\n",
    "    if string == '@':\n",
    "        return 'A'\n",
    "    return 'H'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48066ac",
   "metadata": {},
   "source": [
    "### Making a Dict with each school's name and URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4d7a18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function extracts the number of pages on Maxpreps for each state.\n",
    "def get_num_pages(state):\n",
    "    current_page = 1\n",
    "    while True:\n",
    "        url = f'https://www.maxpreps.com/{state}/basketball/21-22/rankings/{current_page}/'\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        next_page_button = soup.find_all('a', class_ = 'btn btn-default')\n",
    "        button = [butt.text for butt in next_page_button]\n",
    "        num = str(current_page + 1)\n",
    "        if num not in button:\n",
    "            return int(num)- 1\n",
    "        current_page += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79c4feac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function will extract \n",
    "def extract_state_ranking_page(state, current_page):\n",
    "    url = f'https://www.maxpreps.com/{state}/basketball/21-22/rankings/{current_page}/'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text , 'html.parser')\n",
    "    school_elements = soup.find_all('th', class_='school')\n",
    "    school_elements.pop(0)\n",
    "    school_links = [school.find('a').get('href') for school in school_elements]\n",
    "    return dict(zip((school.text for school in school_elements), school_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f6edc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function will create a dictionary of schools and their respective links given a state.\n",
    "def create_school_dict(state):\n",
    "    school_dict = {}\n",
    "    num_pages = get_num_pages(state)\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        future_to_page = {executor.submit(extract_state_ranking_page, state, page): page for page in range(1, num_pages + 1)}\n",
    "        for future in concurrent.futures.as_completed(future_to_page):\n",
    "            try:\n",
    "                page = future_to_page[future]\n",
    "                data = future.result()\n",
    "                school_dict.update(data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching page {page}: {e}\")\n",
    "    return school_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3239f988",
   "metadata": {},
   "source": [
    "### Mascot Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "075dfede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The purpose of extracting the mascot for each school is to give each school a unique indentifer that will later be used get the location and address of team 2.\n",
    "def extractMascots(soup):\n",
    "    src_links = []\n",
    "    #soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    div_elements = soup.find_all('div', class_='sc-3a367303-0 guEKkV')\n",
    "    \n",
    "    for div in div_elements:\n",
    "        img_element = div.find('img', class_='sc-e055731c-0 TgzVI photo-or-initial')\n",
    "        if img_element:\n",
    "            src_links.append(img_element.get('src'))\n",
    "        else:\n",
    "            src_links.append(None)\n",
    "    \n",
    "    return src_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01933a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatMascot(string):\n",
    "    if string is not None:\n",
    "        output_string = string.replace('width=32&height=32', 'width=64&height=64')\n",
    "        return output_string\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c91bc4",
   "metadata": {},
   "source": [
    "### Sports Offered Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4999014a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function extracts the sports offered at a given school for both boys and girls. It takes in the school URL as input\n",
    "def extractSports(url):\n",
    "    url = f'http://www.maxpreps.com{url}'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "    elements = soup.find_all('div', class_ = 'sports-list-child')\n",
    "\n",
    "    boys = []\n",
    "    girls = []\n",
    "    #check if school offers no sports\n",
    "    if len(elements) == 0:\n",
    "        return None\n",
    "\n",
    "    for element in elements:\n",
    "        gender = element.find('h2', class_ = 'sc-23c90da8-0 KWggY')\n",
    "        sports = element.find_all('span', class_ = 'sport-name')\n",
    "        if gender.text == 'Boys':\n",
    "            for sport in sports:\n",
    "                boys.append(sport.text)\n",
    "        else:\n",
    "            for sport in sports:\n",
    "                girls.append(sport.text)\n",
    "                \n",
    "    return ','.join(boys), ','.join(girls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112c9984",
   "metadata": {},
   "source": [
    "### Merging DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7747494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will create a df that has the location and address of team 2. Merging was perfomed on the mascot column.\n",
    "def mergeDF(df):\n",
    "    df['Team 1 Mascot'] = df['Team 1 Mascot'].astype(str)\n",
    "    df['Team 2 Mascot'] = df['Team 2 Mascot'].astype(str)\n",
    "    df['Team 2 Mascot'] = df['Team 2 Mascot'].apply(formatMascot)\n",
    "    X = df.loc[:, ['Team 1 Address', 'Team 1 City', 'Team 1 State', 'Team 1 Zipcode', 'Team 1 Mascot']]\n",
    "    X = X.rename(columns={'Team 1 Address': 'Team 2 Address',\n",
    "                                   'Team 1 City': 'Team 2 City',\n",
    "                                   'Team 1 State': 'Team 2 State',\n",
    "                                   'Team 1 Zipcode': 'Team 2 Zipcode',\n",
    "                                     'Team 1 Mascot': 'Team 2 Mascot'})\n",
    "    X = X.drop_duplicates()\n",
    "    X = X[X['Team 2 Mascot'] != 'None']\n",
    "    merged_df = pd.merge(df, X, how = 'left', left_on = 'Team 2 Mascot', right_on = 'Team 2 Mascot')\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c8eb0b",
   "metadata": {},
   "source": [
    "### Put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ba33e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from tenacity import retry, stop_after_attempt, wait_fixed\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "802f7320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tenacity import retry, stop_after_attempt, wait_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2df9bb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function utilizes all previous functions. it will read in the school name and url, scrape the data, and clean everything up to a useable format.\n",
    "\n",
    "@retry(stop=stop_after_attempt(5), wait=wait_fixed(3))\n",
    "def scrape_school_data(school, url):\n",
    "    try:\n",
    "        school_url = f'http://www.maxpreps.com{url}'\n",
    "        #print(school_url)\n",
    "        response = requests.get(school_url).text\n",
    "        soup = BeautifulSoup(response, 'lxml')\n",
    "        table = soup.find('table')\n",
    "        data = pd.read_html(str(table))[0]\n",
    "        data = data.drop('Game Info', axis=1)\n",
    "        data['Team 1'] = school\n",
    "        data['Team 1 Location'] = extractLocation(soup)\n",
    "        data['Team 1 Address'] = extractAddress(soup)\n",
    "        data['Team 1 City'] = splitLocation(data['Team 1 Location'])[0]\n",
    "        data['Team 1 State'] = splitLocation(data['Team 1 Location'])[1]\n",
    "        data['Team 1 Zipcode'] = splitLocation(data['Team 1 Location'])[2]\n",
    "        data['Venue'] = gameInfo(data['Opponent'])[0].apply(cleanVenueType)\n",
    "        data['Team 2'] = gameInfo(data['Opponent'])[1]\n",
    "        data['Game Type'] = gameInfo(data['Opponent'])[2].apply(cleanGameType)\n",
    "        data['Outcome'] = scoreInfo(data['Result'])[0]\n",
    "        data['Team 1 Score'] = scoreInfo(data['Result'])[1]\n",
    "        data['Team 2 Score'] = scoreInfo(data['Result'])[2]\n",
    "        team1_mascot = soup.find('img', class_ = 'sc-e055731c-0 ddWTnk photo-or-initial')\n",
    "        if team1_mascot:  \n",
    "            data['Team 1 Mascot'] = team1_mascot.get('src')\n",
    "        else:\n",
    "            data['Team 1 Mascot'] = None\n",
    "        team_2_mascots = extractMascots(soup)\n",
    "        data['Team 2 Mascot'] = team_2_mascots\n",
    "        sports_url = url.rsplit('/', 4)[0] + '/'\n",
    "        #print(sports_url)\n",
    "        sports_offered = extractSports(sports_url)\n",
    "        data['Boys Sports'] = sports_offered[0]\n",
    "        data['Girls Sports'] = sports_offered[1]\n",
    "\n",
    "        return data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {school}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c20aee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is given a state and a dictionary of schools and their urls. It will scrape all the schools in the dictionary and return a dataframe with all the data.\n",
    "def scrape_all_schools_async(school_dict, state):\n",
    "\n",
    "    grand_df = pd.DataFrame()\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = [executor.submit(scrape_school_data, school, url) for school, url in school_dict.items()]\n",
    "\n",
    "        with tqdm(total=len(futures), desc=f\"Scraping Schools for {state}\", unit=\" schools\") as pbar:\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                data = future.result()\n",
    "                if data is not None:\n",
    "                    grand_df = pd.concat([grand_df, data], ignore_index=True)\n",
    "                pbar.update(1)\n",
    "\n",
    "    return grand_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3269f1",
   "metadata": {},
   "source": [
    "### Running It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ca5385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Date', 'Team 1', 'Team 2', 'Venue', 'Game Type', 'Team 1 Score', \n",
    "       'Team 2 Score', 'Outcome', 'Team 1 Address', 'Team 1 City',\n",
    "       'Team 1 State', 'Team 1 Zipcode','Team 2 Address','Team 2 City',\n",
    "        'Team 2 State', 'Team 2 Zipcode', 'Boys Sports', 'Girls Sports', ]\n",
    "merged = merged[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f6494f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values = merged.isnull()\n",
    "\n",
    "# Sum the null values for each column\n",
    "null_counts = null_values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "77e5427d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for ak: 100%|██████████| 114/114 [00:14<00:00,  7.73 schools/s]\n",
      "Scraping Schools for al: 100%|██████████| 477/477 [01:15<00:00,  6.33 schools/s]\n",
      "Scraping Schools for ar: 100%|██████████| 294/294 [00:43<00:00,  6.70 schools/s]\n",
      "Scraping Schools for az:  59%|█████▉    | 193/328 [00:29<00:19,  6.79 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing PHH Prep Open (Phoenix): No tables found\n",
      "Error processing PHH Prep National (Phoenix): No tables found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for az: 100%|██████████| 328/328 [00:48<00:00,  6.72 schools/s]\n",
      "Scraping Schools for ca:  50%|████▌    | 718/1428 [01:49<02:09,  5.49 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Liberty Charter (Alpine): HTTPConnectionPool(host='www.maxpreps.com', port=80): Max retries exceeded with url: /ca/alpine/liberty-charter-lions/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc2e0ca9a00>: Failed to establish a new connection: [Errno 60] Operation timed out'))Error processing Liberty (Madera): HTTPSConnectionPool(host='www.maxpreps.com', port=443): Max retries exceeded with url: /ca/madera/liberty-hawks/ (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fc2dfc20f70>: Failed to establish a new connection: [Errno 60] Operation timed out'))\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for ca:  64%|█████▋   | 907/1428 [02:20<01:09,  7.51 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Northgate (Walnut Creek): HTTPConnectionPool(host='www.maxpreps.com', port=80): Max retries exceeded with url: /ca/walnut-creek/northgate-broncos/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc2e5c28280>: Failed to establish a new connection: [Errno 60] Operation timed out'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for ca: 100%|████████| 1428/1428 [03:48<00:00,  6.24 schools/s]\n",
      "Scraping Schools for co: 100%|██████████| 343/343 [00:56<00:00,  6.02 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Two Roads Charter School (Arvada): HTTPConnectionPool(host='www.maxpreps.com', port=80): Max retries exceeded with url: /co/arvada/two-roads-charter-school-falcons/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc2e43d82e0>: Failed to establish a new connection: [Errno 60] Operation timed out'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraping Schools for ct: 100%|██████████| 184/184 [00:27<00:00,  6.57 schools/s]\n",
      "Scraping Schools for de: 100%|████████████| 60/60 [00:08<00:00,  7.33 schools/s]\n",
      "Scraping Schools for fl:  26%|██▋       | 203/772 [00:29<01:26,  6.58 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing DME Academy Blue (Daytona Beach): HTTPConnectionPool(host='www.maxpreps.com', port=80): Max retries exceeded with url: /fl/daytona-beach/dme-academy-blue-dme-academy/basketball/21-22/schedule/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc2e1bf9490>: Failed to establish a new connection: [Errno 60] Operation timed out'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for fl:  66%|██████▌   | 506/772 [01:19<00:34,  7.72 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Osceola Christian Prep (Kissimmee): No tables found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for fl:  86%|████████▌ | 665/772 [01:43<00:11,  9.03 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Somerset Academy Central Miramar (Miramar): HTTPSConnectionPool(host='www.maxpreps.com', port=443): Max retries exceeded with url: /fl/miramar/somerset-academy-central-miramar-warriors/basketball/21-22/schedule/ (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fc2e6cb75e0>: Failed to establish a new connection: [Errno 60] Operation timed out'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for fl: 100%|██████████| 772/772 [01:59<00:00,  6.46 schools/s]\n",
      "Scraping Schools for ga:  66%|██████▌   | 384/580 [00:59<00:22,  8.83 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Montgomery County (Mt. Vernon): HTTPSConnectionPool(host='www.maxpreps.com', port=443): Max retries exceeded with url: /ga/mt-vernon/montgomery-county-eagles/basketball/21-22/schedule/ (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fc2e22fd160>: Failed to establish a new connection: [Errno 60] Operation timed out'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for ga: 100%|██████████| 580/580 [01:29<00:00,  6.48 schools/s]\n",
      "Scraping Schools for hi: 100%|████████████| 57/57 [00:07<00:00,  7.93 schools/s]\n",
      "Scraping Schools for ia:  67%|██████▋   | 242/362 [00:31<00:15,  7.59 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Melcher-Dallas (Melcher): HTTPConnectionPool(host='www.maxpreps.com', port=80): Max retries exceeded with url: /ia/melcher/melcher-dallas-saints/basketball/21-22/schedule/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc2fada7070>: Failed to establish a new connection: [Errno 60] Operation timed out'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for ia: 100%|██████████| 362/362 [00:46<00:00,  7.73 schools/s]\n",
      "Scraping Schools for id: 100%|██████████| 157/157 [00:19<00:00,  8.02 schools/s]\n",
      "Scraping Schools for il:  18%|█▊        | 143/774 [00:20<01:46,  5.90 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Crossroads Christian (Big Rock): No tables found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for il: 100%|██████████| 774/774 [01:51<00:00,  6.95 schools/s]\n",
      "Scraping Schools for in: 100%|██████████| 460/460 [01:04<00:00,  7.09 schools/s]\n",
      "Scraping Schools for ks: 100%|██████████| 372/372 [00:49<00:00,  7.51 schools/s]\n",
      "Scraping Schools for ky: 100%|██████████| 281/281 [00:40<00:00,  7.02 schools/s]\n",
      "Scraping Schools for la: 100%|██████████| 396/396 [00:55<00:00,  7.17 schools/s]\n",
      "Scraping Schools for ma: 100%|██████████| 341/341 [00:45<00:00,  7.43 schools/s]\n",
      "Scraping Schools for md: 100%|██████████| 280/280 [00:35<00:00,  7.96 schools/s]\n",
      "Scraping Schools for me: 100%|██████████| 133/133 [00:17<00:00,  7.80 schools/s]\n",
      "Scraping Schools for mi:  33%|███▎      | 244/735 [00:32<00:54,  9.04 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dundee: HTTPConnectionPool(host='www.maxpreps.com', port=80): Max retries exceeded with url: /mi/dundee/dundee-vikings/basketball/21-22/schedule/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc2e3da04f0>: Failed to establish a new connection: [Errno 60] Operation timed out'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for mi:  52%|█████▏    | 380/735 [00:51<00:45,  7.75 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Ida: HTTPConnectionPool(host='www.maxpreps.com', port=80): Max retries exceeded with url: /mi/ida/ida-bluestreaks/basketball/21-22/schedule/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc2e5323460>: Failed to establish a new connection: [Errno 60] Operation timed out'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for mi:  69%|██████▉   | 507/735 [01:08<00:30,  7.59 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Michigan Math & Science (Center Line): HTTPSConnectionPool(host='www.maxpreps.com', port=443): Max retries exceeded with url: /mi/center-line/michigan-math-and-science/ (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fc2fc363430>: Failed to establish a new connection: [Errno 60] Operation timed out'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for mi:  87%|████████▋ | 636/735 [01:27<00:17,  5.78 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Summit Academy North (Romulus): No tables found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for mi: 100%|██████████| 735/735 [01:40<00:00,  7.30 schools/s]\n",
      "Scraping Schools for mn:  61%|██████    | 263/434 [00:36<00:24,  6.86 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Litchfield: HTTPConnectionPool(host='www.maxpreps.com', port=80): Max retries exceeded with url: /mn/litchfield/litchfield-dragons/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc2e22ed9d0>: Failed to establish a new connection: [Errno 60] Operation timed out'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for mn: 100%|██████████| 434/434 [01:00<00:00,  7.22 schools/s]\n",
      "Scraping Schools for mo:  50%|████▉     | 300/601 [00:40<00:36,  8.28 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Kingston (Cadet): HTTPSConnectionPool(host='www.maxpreps.com', port=443): Max retries exceeded with url: /mo/cadet/kingston-cougars/ (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fc2e1687d90>: Failed to establish a new connection: [Errno 60] Operation timed out'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for mo:  68%|██████▊   | 411/601 [00:55<00:20,  9.25 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing North Andrew (Rosendale): HTTPSConnectionPool(host='www.maxpreps.com', port=443): Max retries exceeded with url: /mo/rosendale/north-andrew-cardinals/basketball/21-22/schedule/ (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fc2e64b1dc0>: Failed to establish a new connection: [Errno 60] Operation timed out'))\n",
      "Error processing Neosho: HTTPSConnectionPool(host='www.maxpreps.com', port=443): Max retries exceeded with url: /mo/neosho/neosho-wildcats/ (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fc2e64b1ee0>: Failed to establish a new connection: [Errno 60] Operation timed out'))\n",
      "Error processing New Bloomfield: HTTPConnectionPool(host='www.maxpreps.com', port=80): Max retries exceeded with url: /mo/new-bloomfield/new-bloomfield-wildcats/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc2e2f811c0>: Failed to establish a new connection: [Errno 60] Operation timed out'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for mo:  72%|███████▏  | 433/601 [00:58<00:21,  7.80 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Northwest (Cedar Hill): HTTPSConnectionPool(host='www.maxpreps.com', port=443): Max retries exceeded with url: /mo/cedar-hill/northwest-lions/ (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fc2fa84d4c0>: Failed to establish a new connection: [Errno 60] Operation timed out'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for mo:  91%|█████████▏| 549/601 [01:15<00:07,  6.96 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing St. Francis Borgia (Washington): HTTPConnectionPool(host='www.maxpreps.com', port=80): Max retries exceeded with url: /mo/washington/st-francis-borgia-knights/basketball/21-22/schedule/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc2e3f2b610>: Failed to establish a new connection: [Errno 60] Operation timed out'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for mo: 100%|██████████| 601/601 [01:21<00:00,  7.34 schools/s]\n",
      "Scraping Schools for ms: 100%|██████████| 316/316 [00:42<00:00,  7.52 schools/s]\n",
      "Scraping Schools for mt: 100%|██████████| 158/158 [00:22<00:00,  6.98 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing St. Regis: HTTPConnectionPool(host='www.maxpreps.com', port=80): Max retries exceeded with url: /mt/st-regis/st-regis-tigers/basketball/21-22/schedule/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc2fc24aca0>: Failed to establish a new connection: [Errno 60] Operation timed out'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraping Schools for nc:  88%|████████▊ | 574/652 [01:22<00:08,  9.27 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Valor Preparatory Academy (Concord): No tables found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for nc: 100%|██████████| 652/652 [01:34<00:00,  6.92 schools/s]\n",
      "Scraping Schools for nd: 100%|██████████| 122/122 [00:15<00:00,  7.63 schools/s]\n",
      "Scraping Schools for ne: 100%|██████████| 283/283 [00:38<00:00,  7.39 schools/s]\n",
      "Scraping Schools for nh: 100%|████████████| 88/88 [00:11<00:00,  7.89 schools/s]\n",
      "Scraping Schools for nj: 100%|██████████| 423/423 [00:57<00:00,  7.35 schools/s]\n",
      "Scraping Schools for nm: 100%|██████████| 150/150 [00:21<00:00,  6.92 schools/s]\n",
      "Scraping Schools for nv: 100%|██████████| 114/114 [00:21<00:00,  5.20 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Truckee: HTTPConnectionPool(host='www.maxpreps.com', port=80): Max retries exceeded with url: /ca/truckee/truckee-wolverines/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc2fb5f31f0>: Failed to establish a new connection: [Errno 60] Operation timed out'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraping Schools for ny:  23%|██▎       | 138/597 [00:17<00:44, 10.31 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Dundee: No tables found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for ny:  71%|███████   | 422/597 [00:53<00:20,  8.73 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Pittsford: No tables found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for ny: 100%|██████████| 597/597 [01:16<00:00,  7.80 schools/s]\n",
      "Scraping Schools for oh:  34%|███▍      | 290/856 [00:40<01:01,  9.20 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Euclid: HTTPConnectionPool(host='www.maxpreps.com', port=80): Max retries exceeded with url: /oh/euclid/euclid-panthers/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc2fa7ed4f0>: Failed to establish a new connection: [Errno 60] Operation timed out'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for oh: 100%|██████████| 856/856 [02:02<00:00,  7.01 schools/s]\n",
      "Scraping Schools for ok: 100%|██████████| 483/483 [01:00<00:00,  7.97 schools/s]\n",
      "Scraping Schools for or: 100%|██████████| 266/266 [00:34<00:00,  7.76 schools/s]\n",
      "Scraping Schools for pa:  46%|████▌     | 336/738 [00:46<00:50,  7.97 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Holy Redeemer (Wilkes-Barre): HTTPConnectionPool(host='www.maxpreps.com', port=80): Max retries exceeded with url: /pa/wilkes-barre/holy-redeemer-royals/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc2e1deb340>: Failed to establish a new connection: [Errno 60] Operation timed out'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for pa: 100%|██████████| 738/738 [01:43<00:00,  7.16 schools/s]\n",
      "Scraping Schools for ri: 100%|████████████| 52/52 [00:07<00:00,  6.74 schools/s]\n",
      "Scraping Schools for sc: 100%|██████████| 301/301 [00:41<00:00,  7.23 schools/s]\n",
      "Scraping Schools for sd: 100%|██████████| 158/158 [00:20<00:00,  7.80 schools/s]\n",
      "Scraping Schools for tn: 100%|██████████| 432/432 [00:59<00:00,  7.31 schools/s]\n",
      "Scraping Schools for tx:  13%|█▏       | 227/1688 [00:33<02:34,  9.46 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Brookeland: HTTPConnectionPool(host='www.maxpreps.com', port=80): Max retries exceeded with url: /tx/brookeland/brookeland-wildcats/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc2e666c9d0>: Failed to establish a new connection: [Errno 60] Operation timed out'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for tx:  44%|███▉     | 740/1688 [01:52<02:51,  5.52 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Hondo: HTTPConnectionPool(host='www.maxpreps.com', port=80): Max retries exceeded with url: /tx/hondo/hondo-owls/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc2e2b97f10>: Failed to establish a new connection: [Errno 60] Operation timed out'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for tx:  64%|█████   | 1080/1688 [02:49<01:47,  5.65 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Montgomery: HTTPConnectionPool(host='www.maxpreps.com', port=80): Max retries exceeded with url: /tx/montgomery/montgomery-bears/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc2e6bffd60>: Failed to establish a new connection: [Errno 60] Operation timed out'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for tx:  68%|█████▍  | 1140/1688 [03:00<01:55,  4.73 schools/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing Parkview Christian (Waco): No tables found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Schools for tx: 100%|████████| 1688/1688 [04:35<00:00,  6.14 schools/s]\n",
      "Scraping Schools for ut: 100%|██████████| 142/142 [00:19<00:00,  7.11 schools/s]\n",
      "Scraping Schools for va: 100%|██████████| 437/437 [00:58<00:00,  7.42 schools/s]\n",
      "Scraping Schools for vt: 100%|████████████| 64/64 [00:09<00:00,  7.01 schools/s]\n",
      "Scraping Schools for wa: 100%|██████████| 380/380 [00:49<00:00,  7.66 schools/s]\n",
      "Scraping Schools for wi: 100%|██████████| 506/506 [01:09<00:00,  7.28 schools/s]\n",
      "Scraping Schools for wv: 100%|██████████| 126/126 [00:16<00:00,  7.59 schools/s]\n",
      "Scraping Schools for wy: 100%|████████████| 67/67 [00:09<00:00,  6.78 schools/s]\n"
     ]
    }
   ],
   "source": [
    "states = [\n",
    "    \"ak\", \"al\", \"ar\", \"az\", \"ca\", \"co\", \"ct\", \"dc\", \"de\", \"fl\", \"ga\",\n",
    "    \"hi\", \"ia\", \"id\", \"il\", \"in\", \"ks\", \"ky\", \"la\", \"ma\", \"md\",\n",
    "    \"me\", \"mi\", \"mn\", \"mo\", \"ms\", \"mt\", \"nc\", \"nd\", \"ne\", \"nh\",\n",
    "    \"nj\", \"nm\", \"nv\", \"ny\", \"oh\", \"ok\", \"or\", \"pa\", \"ri\", \"sc\",\n",
    "    \"sd\", \"tn\", \"tx\", \"ut\", \"va\", \"vt\", \"wa\", \"wi\", \"wv\", \"wy\"\n",
    "]\n",
    "\n",
    "#this loop:\n",
    "#(1) iterates through each state\n",
    "#(2) in each iteration a school dictionary is created with school as key and url as value\n",
    "#(3) the data is scraped for each school in the dictionary\n",
    "#(4) Team 2 Location and Address is addeed using the mergeDF function\n",
    "#(5) columns are reordered\n",
    "#(6) the data for each state is saved in its own csv file\n",
    "for state in states:\n",
    "    school_dict = create_school_dict(state)\n",
    "    school_dict = {k: school_dict[k] for k in sorted(school_dict)}\n",
    "    #print(school_dict)\n",
    "    data = scrape_all_schools_async(school_dict, state)\n",
    "    merged = mergeDF(data)\n",
    "    cols = ['Date', 'Team 1', 'Team 2', 'Venue', 'Game Type', 'Team 1 Score', \n",
    "       'Team 2 Score', 'Outcome', 'Team 1 Address', 'Team 1 City',\n",
    "       'Team 1 State', 'Team 1 Zipcode','Team 2 Address','Team 2 City',\n",
    "        'Team 2 State', 'Team 2 Zipcode', 'Boys Sports', 'Girls Sports',\n",
    "        'Team 1 Mascot', 'Team 2 Mascot']\n",
    "    merged = merged[cols]\n",
    "    merged.to_csv(f'{state}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
